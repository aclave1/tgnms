<system>
  workers 4
</system>

<source>
  @type prometheus
  port 24231
  bind 0.0.0.0
</source>

<source>
  @type prometheus_monitor
</source>

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type http
  port 24221
  bind 0.0.0.0
  body_size_limit 32m
  keepalive_timeout 10s
</source>

{% for controller in controllers_list %}
<worker 0>
  <source>
    @type tail
    tag temp.{{ controller.name | trim | replace(' ', '_') | lower }}
    path /audit/{{ controller.name | trim | replace(' ', '_') | lower }}/api_audit.logs
    pos_file /audit/audit.log.pos
    <parse>
      @type json
    </parse>
  </source>
</worker>

<filter temp.{{ controller.name | trim | replace(' ', '_') | lower }}>
  @type record_transformer
  <record>
    tag log.server.e2e.audit
    topology_name {{ controller.name }}
  </record>
</filter>

{% endfor %}

<worker 1>
  <source>
    @type kafka
    brokers kafka:9092
    topics events
  </source>
</worker>

# Ignore fluentd logs
<match fluent.*>
  @type null
</match>

<filter events>
  @type record_transformer
  remove_keys timestamp,nodeId,eventId,nodeName,topologyName
  <record>
    @timestamp ${record["timestamp"]}
    node_id ${record["nodeId"]}
    event_id ${record["eventId"]}
    node_name ${record["nodeName"]}
    topology_name ${record["topologyName"]}
  </record>
</filter>

<filter log.node.*>
  @type record_transformer
  <record>
    log_file ${tag_parts[2]}
    es_index node-${tag_parts[2]}
  </record>
</filter>

<filter log.server.**>
  @type record_transformer
  <record>
    es_index server
  </record>
</filter>

<filter log.server.e2e.*>
  @type record_transformer
  remove_keys fluentd.topology_name,com.docker.swarm.service.name
  <record>
    topology_name ${record["fluentd.topology_name"]}
    docker_service_name ${record["com.docker.swarm.service.name"]}
  </record>
</filter>

<match events>
  @type elasticsearch
  <buffer tag>
    @type memory
    flush_thread_count 2
    flush_interval 5s
    flush_mode interval
    total_limit_size 2GB
  </buffer>
  hosts elasticsearch:9200
  logstash_format true
  logstash_prefix fluentd-event
  reconnect_on_error true
  reload_on_failure true
  reload_connections false
  with_transporter_log true
  request_timeout 15s
  log_es_400_reason true
</match>

<match log.**>
  @type elasticsearch
  <buffer tag, es_index>
    @type memory
    flush_thread_count 2
    flush_interval 5s
    flush_mode interval
    total_limit_size 2GB
    # timekey 3600
  </buffer>
  hosts elasticsearch:9200
  logstash_format true
  logstash_prefix fluentd-log-${es_index}
  include_timestamp true
  include_tag_key true
  tag_key @log_name
  reconnect_on_error true
  reload_on_failure true
  reload_connections false
  with_transporter_log true
  request_timeout 15s
  log_es_400_reason true
  # @log_level debug
</match>
